# ğŸš€ PROMPT UPGRADER SYSTEM - PROJECT MEMORY

> **Auto-loaded má»—i conversation má»›i!**
> Last updated: 2025-11-10

---

## ğŸ“‹ PROJECT STATUS

**Current Phase:** Phase 6 - Complete (100%)
**Next Phase:** Phase 7 - Prompt Versioning & AB Testing
**Total Timeline:** 24 days (10 phases)
**Last Audit:** 2025-11-10 - ALL TESTS PASSED âœ…

---

## ğŸ¯ WHAT WE'RE BUILDING

**Enterprise Prompt Upgrader System** - Há»‡ thá»‘ng nÃ¢ng cáº¥p prompt tá»± Ä‘á»™ng vá»›i:

### Core Features (Days 1-9):
1. âœ… Prompt Augmentation Pipeline
2. âœ… RAG Integration (Pinecone vector DB)
3. âœ… Conversation Summarizer
4. âœ… Multi-tenant Isolation
5. âœ… Cost Optimization

### Enterprise Features (Days 10-24):
6. âœ… Multi-tenant AuthN/Z + Quotas
7. âœ… Prompt Versioning & AB Testing (Canary Rollout)
8. âœ… Evals & Red-teaming (Automated Quality Tests)
9. âœ… Advanced Observability (Prometheus + Sentry)
10. âœ… Security Guardrails (PII + Injection Defense)

---

## ğŸ—ï¸ ARCHITECTURE

```
User Query
    â†“
[PII Redaction]
    â†“
[Parallel Gathering]
â”œâ”€ Conversation Summary (GPT-4o-mini, cached)
â”œâ”€ RAG Retrieval (Pinecone vector search)
â””â”€ Context Merge
    â†“
[Prompt Upgrader Agent] (GPT-4o-mini, JSON output)
    â†“
{
  final_prompt: "ROLE/TASK/CONTEXT/CONSTRAINTS/FORMAT",
  reasoning: "...",
  missing_questions: [...]
}
    â†“
[Main LLM] (GPT-4 / Claude 3.5)
    â†“
[PII Restore]
    â†“
Response to User
```

---

## ğŸ“‚ NEW SERVICE STRUCTURE

```
backend/services/orchestrator-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/              # AI Agents
â”‚   â”‚   â”œâ”€â”€ summarizer.agent.ts
â”‚   â”‚   â”œâ”€â”€ rag-retriever.agent.ts
â”‚   â”‚   â””â”€â”€ prompt-upgrader.agent.ts
â”‚   â”œâ”€â”€ services/            # Core Services
â”‚   â”‚   â”œâ”€â”€ embedding.service.ts
â”‚   â”‚   â”œâ”€â”€ vector-store.service.ts
â”‚   â”‚   â”œâ”€â”€ pii-redaction.service.ts
â”‚   â”‚   â”œâ”€â”€ orchestrator.service.ts
â”‚   â”‚   â”œâ”€â”€ canary-rollout.service.ts
â”‚   â”‚   â”œâ”€â”€ eval-runner.service.ts
â”‚   â”‚   â””â”€â”€ fallback.service.ts
â”‚   â”œâ”€â”€ prompts/             # Prompt Templates
â”‚   â”‚   â”œâ”€â”€ summarizer.prompt.ts
â”‚   â”‚   â””â”€â”€ upgrader.prompt.ts
â”‚   â”œâ”€â”€ middleware/          # Middleware
â”‚   â”‚   â”œâ”€â”€ quota.middleware.ts
â”‚   â”‚   â”œâ”€â”€ rbac.middleware.ts
â”‚   â”‚   â”œâ”€â”€ metering.middleware.ts
â”‚   â”‚   â””â”€â”€ rate-limit.middleware.ts
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â””â”€â”€ orchestrator.controller.ts
â”‚   â””â”€â”€ jobs/
â”‚       â””â”€â”€ nightly-evals.ts
â”œâ”€â”€ prisma/
â”‚   â””â”€â”€ schema.prisma        # 10+ models
â””â”€â”€ tests/
```

---

## ğŸ—„ï¸ DATABASE MODELS (New)

1. **TenantPlan** - Quotas & billing
2. **UsageMeter** - Token tracking per component
3. **TenantRole** - RBAC (OWNER/ADMIN/MEMBER/VIEWER)
4. **PromptTemplate** - Versioned prompts
5. **PromptRun** - AB test tracking
6. **EvalDataset** - Test cases
7. **EvalQuestion** - Individual tests
8. **EvalRun** - Batch eval results
9. **EvalResult** - Per-question scores
10. **KnowledgeBase** - RAG documents

---

## ğŸ“‹ 10 PHASES OVERVIEW

| Phase | Days | Focus | Status |
|-------|------|-------|--------|
| 1 | 1-2 | Core Infrastructure | âœ… Complete |
| 2 | 3-4 | Core Services (PII, Embedding, Vector) | âœ… Complete |
| 3 | 5-6 | AI Agents (Summarizer, RAG, Upgrader) | âœ… Complete |
| 4 | 7-8 | Orchestrator Pipeline | âœ… Complete |
| 5 | 9 | API & Frontend Integration | âœ… Complete |
| 6 | 10-12 | Multi-tenant + Quotas | âœ… Complete |
| 7 | 13-16 | Prompt Versioning & AB Test | ğŸ”„ Partial (canary service exists) |
| 8 | 17-19 | Evals & Red-teaming | ğŸ”„ Partial (models ready) |
| 9 | 20-21 | Observability | ğŸ”„ Partial (logging + Sentry) |
| 10 | 22-24 | Security & Resilience | â³ Pending |

---

## ğŸ’¡ KEY DECISIONS

### Model Selection:
- **Embedding:** text-embedding-3-small ($0.02/1M tokens)
- **Summarizer:** GPT-4o-mini ($0.15/$0.60 per 1M)
- **Upgrader:** GPT-4o-mini ($0.15/$0.60 per 1M)
- **Main LLM:** GPT-4 or Claude 3.5 Sonnet

### Cost Optimization:
- Redis caching (summary + embeddings)
- Batch embedding API calls
- Context truncation (last 10 messages)
- Target: < $0.12 per request

### Canary Strategy:
- 5% â†’ 25% â†’ 50% â†’ 100%
- Auto-rollback if error_rate > 5%
- 24h between increments

### Eval Criteria:
- Relevance â‰¥ 0.7
- Faithfulness â‰¥ 0.8
- Helpfulness â‰¥ 0.6
- Pass rate â‰¥ 90%

---

## ğŸ”§ TECH STACK (New Dependencies)

```json
{
  "@pinecone-database/pinecone": "^2.0.0",
  "tiktoken": "^1.0.15",
  "email-regex": "^5.0.0",
  "phone-regex": "^2.2.11",
  "node-cron": "^3.0.3"
}
```

---

## ğŸ“Š SUCCESS METRICS

**Performance:**
- Latency < 3s (p95)
- Cache hit rate > 60%
- Error rate < 1%

**Quality:**
- Eval pass rate > 90%
- Relevance > 0.8
- Faithfulness > 0.85

**Cost:**
- Per request < $0.15
- Monthly infrastructure < $200

---

## ğŸš¦ NEXT STEPS (When Ready)

1. **Phase 1, Day 1:**
   - Create orchestrator-service directory
   - Setup package.json + tsconfig
   - Init Prisma schema
   - Setup Express server

2. **Phase 1, Day 2:**
   - Implement env config
   - Setup Pinecone connection
   - Test database connection
   - Create health check endpoint

---

## ğŸ“ NOTES FOR NEXT SESSION

### User Preferences:
- Lightweight guardrails (regex-based PII detection)
- Canary rollout (5â†’25â†’50â†’100%)
- Nightly + on-demand evals
- Already have: Sentry + Prometheus/Grafana

### Design Philosophy:
- Cost-conscious (use mini models where possible)
- Production-ready (monitoring, fallbacks, security)
- Incremental rollout (canary deployment)
- Quality-first (automated evals)

---

## ğŸ¯ IMPLEMENTATION STATUS

### âœ… Completed:
- [x] Ultra-analysis & planning
- [x] Architecture design
- [x] Tech stack selection
- [x] Cost optimization strategy
- [x] 10-phase roadmap
- [x] Phase 1: Core Infrastructure (Database, Config, Server)
- [x] Phase 2: Core Services (PII, Embedding, Vector Store)
- [x] Phase 3: AI Agents (Summarizer, RAG, Upgrader)
- [x] Phase 4: Orchestrator Pipeline (Full flow working)
- [x] Phase 5: API & Controllers (All endpoints tested)
- [x] Phase 6: Multi-tenant & Quotas (Usage tracking working)

### ğŸ”„ In Progress:
- [ ] Phase 7: Prompt Versioning (canary service exists)
- [ ] Phase 8: Evals (database models ready)
- [ ] Phase 9: Observability (basic monitoring working)

### â³ Pending:
- Phase 10: Security & Resilience

---

## ğŸ› KNOWN ISSUES / BLOCKERS

### ğŸŸ¡ Issue #1: Pinecone Index Not Found (Non-blocking)
**Severity:** LOW
**Impact:** RAG features disabled, system continues without Pinecone
**Fix:** Create index manually in Pinecone dashboard (10 minutes)

### âš ï¸ Issue #2: Missing Input Validation
**Severity:** MEDIUM
**Impact:** No Zod validation on API inputs
**Fix:** Add validation middleware (1-2 hours)

### âš ï¸ Issue #3: Swagger Not Configured
**Severity:** LOW
**Impact:** No API documentation UI
**Fix:** Configure swagger-jsdoc (2-3 hours)

---

## ğŸ’­ QUESTIONS TO ANSWER LATER

1. Which vector DB? Pinecone vs Weaviate vs Qdrant?
   - **Decision:** Pinecone (simplest API, managed)

2. How many eval test cases?
   - **Decision:** Start with 50, grow to 200+

3. What's the canary increment schedule?
   - **Decision:** 24h between 5% â†’ 25% â†’ 50% â†’ 100%

---

**ğŸ¯ Ready to start Phase 1 when user says "báº¯t Ä‘áº§u"!**
