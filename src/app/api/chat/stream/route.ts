import { NextRequest } from "next/server";
import { prisma } from "@/lib/prisma";
import { requireUserId } from "@/lib/auth";
import { getProvider } from "@/lib/provider";
import { consumeToken } from "@/lib/rateLimit";
import { hashIdempotency } from "@/lib/ids";

export const dynamic = "force-dynamic"; // ƒë·∫£m b·∫£o kh√¥ng b·ªã cache

function sseInit() {
    return {
        headers: {
            "Content-Type": "text/event-stream; charset=utf-8",
            "Cache-Control": "no-cache, no-transform",
            Connection: "keep-alive",
        },
    };
}

function sseLine(obj: any) {
    return `data: ${JSON.stringify(obj)}\n\n`;
}

export async function POST(req: NextRequest) {
    let convoId: string | undefined;

    try {
        const userId = await requireUserId();

        // Rate limit ng·∫Øn h·∫°n
        const rl = consumeToken(`chat:${userId}`, Number(process.env.RATE_PM || 60));
        if (!rl.ok) {
            return new Response(sseLine({ error: "RATE_LIMIT", done: true }), sseInit());
        }

        const body = (await req.json()) as {
            conversationId?: string;
            message: string;
            systemPrompt?: string;
            temperature?: number;
            force?: boolean;
            idempotencyKey?: string;
        };

        if (!body?.message?.trim()) {
            return new Response(sseLine({ error: "EMPTY_MESSAGE", done: true }), sseInit());
        }

        // L·∫•y / t·∫°o conversation TR∆Ø·ªöC
        convoId = body.conversationId;
        if (convoId) {
            const exists = await prisma.conversation.findFirst({ where: { id: convoId, userId } });
            if (!exists) {
                const created = await prisma.conversation.create({
                    data: { userId, title: body.message.slice(0, 80), systemPrompt: body.systemPrompt },
                });
                convoId = created.id;
            }
        } else {
            const created = await prisma.conversation.create({
                data: { userId, title: body.message.slice(0, 80), systemPrompt: body.systemPrompt },
            });
            convoId = created.id;
        }

        // Idempotency theo h·ªôi tho·∫°i + bucket ph√∫t
        const minuteBucket = Math.floor(Date.now() / 60_000);
        let idem =
            body.idempotencyKey ||
            hashIdempotency({ userId, conversationId: convoId, m: body.message, bucket: minuteBucket });

        const dup = await prisma.message.findFirst({ where: { idempotencyKey: idem } });
        if (dup && !body.force) {
            // ƒê√£ x·ª≠ l√Ω tr∆∞·ªõc ƒë√≥ -> stream l·∫°i c√¢u tr·∫£ l·ªùi g·∫ßn nh·∫•t (1 ph√°t)
            const last = await prisma.message.findFirst({
                where: { conversationId: dup.conversationId, role: "ASSISTANT" },
                orderBy: { createdAt: "desc" },
            });

            const stream = new ReadableStream({
                start(controller) {
                    const enc = new TextEncoder();
                    // üëá b√°o meta tr∆∞·ªõc
                    controller.enqueue(enc.encode(`data: ${JSON.stringify({ meta: { conversationId: convoId, cached: true } })}\n\n`));

                    controller.enqueue(enc.encode(`data: ${JSON.stringify({ contentDelta: last?.content || "[Empty previous assistant message]" })}\n\n`));
                    controller.enqueue(enc.encode(`data: ${JSON.stringify({ done: true })}\n\n`));
                    controller.close();
                }

            });

            return new Response(stream, sseInit());
        }

        // N·∫øu mu·ªën x·ª≠ l√Ω ti·∫øp (force ho·∫∑c cache r·ªóng) -> ƒë·ªïi key tr√°nh @unique
        if (dup) idem = `${idem}:retry:${Date.now()}`;

        // L∆∞u USER message
        await prisma.message.create({
            data: {
                conversationId: convoId!,
                role: "USER",
                content: body.message,
                idempotencyKey: idem,
            },
        });

        // Chu·∫©n b·ªã l·ªãch s·ª≠
        const history = await prisma.message.findMany({
            where: { conversationId: convoId! },
            orderBy: { createdAt: "asc" },
            take: Number(process.env.MAX_HISTORY || 16),
        });
        const convo = await prisma.conversation.findUnique({ where: { id: convoId! } });
        const messages = [
            ...(convo?.systemPrompt ? [{ role: "system" as const, content: convo.systemPrompt }] : []),
            ...history.map((m) => ({ role: m.role.toLowerCase() as "user" | "assistant", content: m.content })),
        ];

        // MOCK mode: ph√°t v√†i chunk gi·∫£ cho ch·∫Øc
        if (process.env.MOCK_AI === "1") {
            const chunks = [`ƒê√É`, ` NH·∫¨N: "`, body.message, `" (mock)`];
            const stream = new ReadableStream({
                async start(controller) {
                    const enc = new TextEncoder();
                    for (const c of chunks) {
                        controller.enqueue(enc.encode(sseLine({ contentDelta: c })));
                        await new Promise((r) => setTimeout(r, 80));
                    }
                    controller.enqueue(enc.encode(sseLine({ done: true })));

                    // L∆∞u full assistant v√†o DB
                    await prisma.message.create({
                        data: {
                            conversationId: convoId!,
                            role: "ASSISTANT",
                            content: chunks.join(""),
                            model: "mock",
                        },
                    });

                    controller.close();
                },
            });
            return new Response(stream, sseInit());
        }

        // Provider th·∫≠t
        const provider = getProvider();
        const model = process.env.AI_MODEL || "gpt-4o-mini";
        const aiStream = provider.stream({
            model,
            messages,
            temperature: body.temperature ?? 0.3,
        });

        let full = "";

        const stream = new ReadableStream({
            async start(controller) {
                const enc = new TextEncoder();

                try {
                    for await (const chunk of aiStream) {
                        if (chunk.contentDelta) {
                            full += chunk.contentDelta;
                            controller.enqueue(enc.encode(sseLine({ contentDelta: chunk.contentDelta })));
                        }
                        if (chunk.done) break;
                    }

                    const safe = full.trim() || "Xin l·ªói, hi·ªán model kh√¥ng tr·∫£ n·ªôi dung. Vui l√≤ng th·ª≠ l·∫°i.";
                    // L∆∞u assistant v√†o DB
                    await prisma.message.create({
                        data: {
                            conversationId: convoId!,
                            role: "ASSISTANT",
                            content: safe,
                            model,
                        },
                    });

                    controller.enqueue(enc.encode(sseLine({ done: true })));
                    controller.close();
                } catch (err: any) {
                    // ƒë·∫©y l·ªói ra stream cho client bi·∫øt
                    controller.enqueue(enc.encode(sseLine({ error: err?.message || "STREAM_ERROR", done: true })));
                    controller.close();
                }
            },
        });

        return new Response(stream, sseInit());
    } catch (e: any) {
        // L·ªói s·ªõm (ch∆∞a k·ªãp t·∫°o stream) -> tr·∫£ 200 + SSE 1 d√≤ng b√°o l·ªói
        return new Response(sseLine({ error: e?.message || "UNKNOWN", conversationId: convoId, done: true }), sseInit());
    }
}
