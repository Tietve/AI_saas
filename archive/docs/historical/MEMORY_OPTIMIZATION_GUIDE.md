# üß† Memory Optimization Guide - Vercel Serverless

## ‚ö†Ô∏è **V·∫§N ƒê·ªÄ**

Vercel Serverless Functions c√≥ gi·ªõi h·∫°n RAM:
- **Free Plan:** 512MB RAM
- **Pro Plan:** 1024MB - 3008MB RAM

**Project c·ªßa b·∫°n v∆∞·ª£t qu√° 2048MB** ‚Üí C·∫ßn t·ªëi ∆∞u ngay!

---

## üîç **NGUY√äN NH√ÇN T·ªêN RAM**

### **1. Node.js Runtime (512MB-1024MB)**
```typescript
// ‚ùå N·∫∂NG - M·ªçi endpoint ƒë·ªÅu d√πng Node.js
export const runtime = 'nodejs'
```
- Cold start: 500-1000ms
- Memory: 512MB-1024MB
- Prisma Client: ~200MB
- Dependencies: ~300MB

### **2. Prisma Client Loaded Everywhere**
```typescript
// ‚ùå Load Prisma v√†o EVERY endpoint
import { prisma } from '@/lib/prisma'
```
- Prisma Client: ~200MB
- Query engine: ~50MB
- Connection pool: ~100MB

### **3. Message History Buffer**
```typescript
// ‚ùå Load to√†n b·ªô 20 messages v√†o RAM
const recent = await prisma.message.findMany({
  take: HISTORY_LIMIT // 20 messages
})
```

### **4. File Processing**
```typescript
// ‚ùå ƒê·ªçc to√†n b·ªô file v√†o RAM
const data = await fs.readFile(filePath)
const base64 = data.toString('base64') // TƒÉng g·∫•p 1.33x
```

### **5. No Memory Cleanup**
- Kh√¥ng c√≥ garbage collection
- Kh√¥ng c√≥ memory limit checks
- Kh√¥ng c√≥ streaming optimization

---

## ‚úÖ **GI·∫¢I PH√ÅP T·ªêI ∆ØU**

### **1. S·ª≠ D·ª•ng Edge Runtime (50x Nh·∫π H∆°n)** ‚ö°

**Edge Runtime:**
- Memory: **< 128MB** (vs 512MB Node.js)
- Cold start: **50-100ms** (vs 500-1000ms)
- Kh√¥ng support: Prisma, fs, crypto native

**Endpoints n√™n chuy·ªÉn sang Edge:**
- ‚úÖ Health checks
- ‚úÖ CSRF tokens
- ‚úÖ Simple auth checks
- ‚úÖ Rate limiting
- ‚úÖ Static responses

**V√≠ d·ª•:**
```typescript
// ‚úÖ NH·∫∏ - Edge Runtime
export const runtime = 'edge'
export const dynamic = 'force-dynamic'

export async function GET() {
  return new Response(JSON.stringify({ status: 'ok' }), {
    headers: { 'Content-Type': 'application/json' }
  })
}
```

---

### **2. Lazy Load Prisma Client**

**Tr∆∞·ªõc (‚ùå N·∫∂NG):**
```typescript
// EVERY endpoint load Prisma
import { prisma } from '@/lib/prisma'
```

**Sau (‚úÖ NH·∫∏):**
```typescript
// Ch·ªâ load khi c·∫ßn
let prisma: PrismaClient | null = null

function getPrisma() {
  if (!prisma) {
    prisma = new PrismaClient()
  }
  return prisma
}

// S·ª≠ d·ª•ng
const db = getPrisma()
const user = await db.user.findUnique(...)
```

---

### **3. Configure Memory Limits** (vercel.json)

```json
{
  "functions": {
    "src/app/api/chat/**/*.ts": {
      "memory": 1024,
      "maxDuration": 60
    },
    "src/app/api/upload/**/*.ts": {
      "memory": 1024,
      "maxDuration": 30
    },
    "src/app/api/auth/**/*.ts": {
      "memory": 512,
      "maxDuration": 10
    },
    "src/app/api/health/route.ts": {
      "memory": 256,
      "maxDuration": 5
    }
  }
}
```

**L·ª£i √≠ch:**
- T·ªëi ∆∞u cost (ch·ªâ tr·∫£ cho RAM c·∫ßn thi·∫øt)
- Nhanh h∆°n (less memory = faster cold start)
- D·ªÖ debug (bi·∫øt endpoint n√†o t·ªën RAM)

---

### **4. Optimize Message History**

**Tr∆∞·ªõc (‚ùå N·∫∂NG):**
```typescript
// Load 20 messages x 10KB = 200KB
const recent = await prisma.message.findMany({
  take: 20,
  include: {
    attachments: true // +500KB n·∫øu c√≥ files
  }
})
```

**Sau (‚úÖ NH·∫∏):**
```typescript
// Ch·ªâ load fields c·∫ßn thi·∫øt
const recent = await prisma.message.findMany({
  take: 10, // Gi·∫£m t·ª´ 20 ‚Üí 10
  select: {
    role: true,
    content: true,
    // KH√îNG load attachments n·∫øu kh√¥ng c·∫ßn
  }
})
```

---

### **5. Stream File Processing**

**Tr∆∞·ªõc (‚ùå N·∫∂NG):**
```typescript
// ƒê·ªçc to√†n b·ªô 10MB file v√†o RAM
const data = await fs.readFile(filePath)
const base64 = data.toString('base64') // 13MB trong RAM
```

**Sau (‚úÖ NH·∫∏):**
```typescript
// Streaming upload (kh√¥ng load v√†o RAM)
import { createReadStream } from 'fs'

const stream = createReadStream(filePath, { highWaterMark: 64 * 1024 })
// Upload t·ª´ng chunk 64KB
```

---

### **6. Reduce Bundle Size**

**Next.js Config:**
```javascript
// next.config.js
module.exports = {
  experimental: {
    // Tree shaking cho serverless
    serverComponentsExternalPackages: ['@prisma/client']
  },

  webpack: (config, { isServer }) => {
    if (isServer) {
      // Reduce bundle size
      config.optimization.splitChunks = {
        chunks: 'all',
        cacheGroups: {
          prisma: {
            test: /[\\/]node_modules[\\/]@prisma[\\/]/,
            name: 'prisma',
            priority: 10
          }
        }
      }
    }
    return config
  }
}
```

---

### **7. Connection Pooling**

**DATABASE_URL c·∫ßn c√≥:**
```bash
postgresql://user:pass@host/db?
  connection_limit=5&      # Gi·∫£m t·ª´ 10 ‚Üí 5
  pool_timeout=10&         # Timeout nhanh
  connect_timeout=5        # Connect nhanh
```

---

### **8. Memory Monitoring**

**Th√™m v√†o API endpoints:**
```typescript
export async function POST(req: Request) {
  const startMem = process.memoryUsage().heapUsed / 1024 / 1024

  // ... x·ª≠ l√Ω ...

  const endMem = process.memoryUsage().heapUsed / 1024 / 1024
  console.log(`Memory used: ${(endMem - startMem).toFixed(2)}MB`)

  if (endMem > 800) { // C·∫£nh b√°o n·∫øu >800MB
    console.warn(`‚ö†Ô∏è High memory usage: ${endMem.toFixed(2)}MB`)
  }
}
```

---

## üìä **MEMORY BUDGET PER ENDPOINT**

| Endpoint Type | Max Memory | Duration | Runtime |
|---------------|------------|----------|---------|
| **Chat/AI** | 1024MB | 60s | nodejs |
| **Upload** | 1024MB | 30s | nodejs |
| **Auth** | 512MB | 10s | nodejs |
| **CRUD** | 512MB | 10s | nodejs |
| **Health/Static** | 256MB | 5s | edge |

---

## üéØ **ACTION PLAN**

### **Phase 1: Quick Wins (Ngay)** ‚úÖ
- [ ] Add `vercel.json` v·ªõi memory limits
- [ ] Chuy·ªÉn health check sang Edge Runtime
- [ ] Gi·∫£m message history: 20 ‚Üí 10
- [ ] Optimize DATABASE_URL connection pool

### **Phase 2: Medium (1-2 ng√†y)** üü°
- [ ] Lazy load Prisma Client
- [ ] Stream file uploads
- [ ] Reduce bundle size v·ªõi webpack config
- [ ] Add memory monitoring

### **Phase 3: Long-term (1 tu·∫ßn)** üîµ
- [ ] Chuy·ªÉn c√°c simple endpoints sang Edge
- [ ] Implement Redis caching
- [ ] Move file processing sang background jobs
- [ ] Add auto-scaling policies

---

## üß™ **TEST MEMORY USAGE**

### **Local Testing:**
```bash
# Test memory locally
NODE_OPTIONS="--max-old-space-size=512" npm run dev

# Monitor memory
node --expose-gc server.js
```

### **Vercel Production:**
```bash
# View logs
vercel logs <deployment-url>

# Monitor functions
vercel inspect <deployment-url>
```

---

## üìà **EXPECTED RESULTS**

### **Before Optimization:**
- Chat endpoint: **800-1200MB** RAM
- Upload endpoint: **600-800MB** RAM
- Auth endpoint: **400-600MB** RAM
- Cold start: **1000-2000ms**

### **After Optimization:**
- Chat endpoint: **400-600MB** RAM ‚¨áÔ∏è 50%
- Upload endpoint: **300-400MB** RAM ‚¨áÔ∏è 50%
- Auth endpoint: **200-300MB** RAM ‚¨áÔ∏è 50%
- Cold start: **300-500ms** ‚¨áÔ∏è 70%

---

## üö® **TROUBLESHOOTING**

### **Error: Function exceeded memory limit**
```bash
# Solution 1: Increase memory in vercel.json
{
  "functions": {
    "src/app/api/problematic/route.ts": {
      "memory": 1536  # Increase to 1.5GB
    }
  }
}

# Solution 2: Optimize the function
- Reduce data fetched
- Use streaming
- Lazy load dependencies
```

### **Error: Cold start timeout**
```bash
# Solution: Reduce bundle size
- Use Edge Runtime if possible
- Lazy load Prisma
- Remove unused dependencies
```

---

## üìö **T√ÄI LI·ªÜU THAM KH·∫¢O**

- **Vercel Functions:** https://vercel.com/docs/functions
- **Edge Runtime:** https://vercel.com/docs/functions/edge-functions
- **Memory Limits:** https://vercel.com/docs/functions/serverless-functions/runtimes#memory
- **Next.js Optimization:** https://nextjs.org/docs/app/building-your-application/optimizing

---

## ‚úÖ **CHECKLIST**

- [ ] ‚úÖ ƒê√£ t·∫°o `vercel.json` v·ªõi memory limits
- [ ] ‚úÖ ƒê√£ t·∫°o Edge Runtime health check
- [ ] ‚è≥ Chuy·ªÉn simple endpoints sang Edge
- [ ] ‚è≥ Lazy load Prisma Client
- [ ] ‚è≥ Optimize message history
- [ ] ‚è≥ Stream file uploads
- [ ] ‚è≥ Add memory monitoring
- [ ] ‚è≥ Test v·ªõi production data

---

**Generated:** 2025-10-12
**Status:** ‚úÖ Ready to Implement
